{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric columns: Index(['Device Model', 'Operating System', 'Gender'], dtype='object')\n",
      "Fitting 5 folds for each of 180 candidates, totalling 900 fits\n",
      "Best Parameters: {'C': 0.1, 'degree': 3, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Accuracy: 100.00%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        27\n",
      "           2       1.00      1.00      1.00        29\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      1.00      1.00        27\n",
      "           5       1.00      1.00      1.00        23\n",
      "\n",
      "    accuracy                           1.00       140\n",
      "   macro avg       1.00      1.00      1.00       140\n",
      "weighted avg       1.00      1.00      1.00       140\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['user_behavior_scaler.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "df_user_behavior = pd.read_csv(r'D:\\ChildTiming\\data\\user_behavior_dataset.csv')  # replace with actual path\n",
    "\n",
    "# Split into features (X) and target (y)\n",
    "X = df_user_behavior.drop(columns=['User Behavior Class', 'User ID'])\n",
    "y = df_user_behavior['User Behavior Class']\n",
    "\n",
    "# Identify columns with non-numeric data\n",
    "non_numeric_columns = X.select_dtypes(include=['object']).columns\n",
    "print(\"Non-numeric columns:\", non_numeric_columns)\n",
    "\n",
    "# Perform One-Hot Encoding for categorical columns\n",
    "X_encoded = pd.get_dummies(X, columns=non_numeric_columns, drop_first=True)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_encoded)\n",
    "\n",
    "# Split the data into training and testing sets after encoding and scaling\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model\n",
    "svm_model = SVC(random_state=42)\n",
    "\n",
    "# Set up the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'kernel': ['linear', 'rbf', 'poly'],  # Kernel type\n",
    "    'gamma': ['scale', 'auto', 0.1, 1, 10],  # Kernel coefficient\n",
    "    'degree': [3, 5, 7]  # Only relevant for 'poly' kernel\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV to find the best parameters\n",
    "grid_search = GridSearchCV(svm_model, param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters and model\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "best_svm_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = best_svm_model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Classification report for detailed metrics\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the best model and scaler\n",
    "joblib.dump(best_svm_model, 'user_behavior_svm_model_with_hyperparameters.pkl')\n",
    "joblib.dump(scaler, 'user_behavior_scaler.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\princ\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Gender_Female\n- Operating System_Android\n- Operating System_Windows\nFeature names seen at fit time, yet now missing:\n- Device Model_OnePlus 9\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 65\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m user_input_scaled\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Test the model with user input\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m user_input_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mget_user_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m prediction \u001b[38;5;241m=\u001b[39m svm_model_user_behavior\u001b[38;5;241m.\u001b[39mpredict(user_input_scaled)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Output the prediction and the reward/suggestion based on the predicted behavior\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[11], line 60\u001b[0m, in \u001b[0;36mget_user_input\u001b[1;34m()\u001b[0m\n\u001b[0;32m     57\u001b[0m user_input_encoded \u001b[38;5;241m=\u001b[39m user_input_encoded\u001b[38;5;241m.\u001b[39mreindex(columns\u001b[38;5;241m=\u001b[39mexpected_columns, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Scale the user input using the same scaler used during training\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m user_input_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input_encoded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m user_input_scaled\n",
      "File \u001b[1;32mc:\\Users\\princ\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\princ\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:1006\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1003\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1005\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m-> 1006\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1007\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1008\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1009\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1010\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1011\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1012\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[1;32mc:\\Users\\princ\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:580\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    511\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    517\u001b[0m ):\n\u001b[0;32m    518\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    519\u001b[0m \n\u001b[0;32m    520\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 580\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    582\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    583\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    584\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    585\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    586\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\princ\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:507\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    503\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n\u001b[1;32m--> 507\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Gender_Female\n- Operating System_Android\n- Operating System_Windows\nFeature names seen at fit time, yet now missing:\n- Device Model_OnePlus 9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "\n",
    "# Load the pre-trained model and scaler\n",
    "svm_model_user_behavior = joblib.load(r'D:\\ChildTiming\\notebook\\user_behavior_svm_model_with_hyperparameters.pkl')  # Adjust path\n",
    "scaler = joblib.load('user_behavior_scaler.pkl')  # Adjust path\n",
    "\n",
    "# Define the columns the model expects\n",
    "expected_columns = [\n",
    "    'Device Model_Samsung Galaxy S21', 'Device Model_Xiaomi Mi 11', 'Device Model_iPhone 12',\n",
    "    'Operating System_Android', 'Operating System_iOS', 'Operating System_Windows',\n",
    "    'App Usage Time (min/day)', 'Screen On Time (hours/day)', 'Battery Drain (mAh/day)',\n",
    "    'Number of Apps Installed', 'Data Usage (MB/day)', 'Age', 'Gender_Female', 'Gender_Male'\n",
    "]\n",
    "\n",
    "# Function to handle user input\n",
    "def get_user_input():\n",
    "    # Prompt user for input\n",
    "    device_model = input(\"Device Model (e.g., Xiaomi Mi 11): \")\n",
    "    operating_system = input(\"Operating System (e.g., Android): \")\n",
    "    app_usage_time = float(input(\"App Usage Time (min/day): \"))\n",
    "    screen_on_time = float(input(\"Screen On Time (hours/day): \"))\n",
    "    battery_drain = float(input(\"Battery Drain (mAh/day): \"))\n",
    "    num_apps = int(input(\"Number of Apps Installed: \"))\n",
    "    data_usage = float(input(\"Data Usage (MB/day): \"))\n",
    "    age = int(input(\"Age: \"))\n",
    "    gender = input(\"Gender (e.g., Male/Female): \")\n",
    "\n",
    "    # Create a DataFrame with the input values\n",
    "    user_input_df = pd.DataFrame({\n",
    "        'Device Model': [device_model],\n",
    "        'Operating System': [operating_system],\n",
    "        'App Usage Time (min/day)': [app_usage_time],\n",
    "        'Screen On Time (hours/day)': [screen_on_time],\n",
    "        'Battery Drain (mAh/day)': [battery_drain],\n",
    "        'Number of Apps Installed': [num_apps],\n",
    "        'Data Usage (MB/day)': [data_usage],\n",
    "        'Age': [age],\n",
    "        'Gender': [gender]\n",
    "    })\n",
    "\n",
    "    # One-hot encode categorical features (Device Model, Operating System, and Gender)\n",
    "    encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "    categorical_columns = ['Device Model', 'Operating System', 'Gender']\n",
    "    categorical_data = user_input_df[categorical_columns]\n",
    "    categorical_encoded = encoder.fit_transform(categorical_data)\n",
    "\n",
    "    # Convert encoded data back into a DataFrame and concatenate with the rest of the input\n",
    "    categorical_encoded_df = pd.DataFrame(categorical_encoded, columns=encoder.get_feature_names_out(categorical_columns))\n",
    "    user_input_df = user_input_df.drop(columns=categorical_columns)\n",
    "    user_input_encoded = pd.concat([user_input_df, categorical_encoded_df], axis=1)\n",
    "\n",
    "    # Ensure the columns match the training set\n",
    "    user_input_encoded = user_input_encoded.reindex(columns=expected_columns, fill_value=0)\n",
    "\n",
    "    # Scale the user input using the same scaler used during training\n",
    "    user_input_scaled = scaler.transform(user_input_encoded)\n",
    "\n",
    "    return user_input_scaled\n",
    "\n",
    "# Test the model with user input\n",
    "user_input_scaled = get_user_input()\n",
    "prediction = svm_model_user_behavior.predict(user_input_scaled)\n",
    "\n",
    "# Output the prediction and the reward/suggestion based on the predicted behavior\n",
    "print(\"Predicted User Behavior:\", prediction[0])\n",
    "\n",
    "if prediction[0] == 5:\n",
    "    print(\"Inform parents: High engagement detected. Please monitor screen time.\")\n",
    "elif prediction[0] == 4:\n",
    "    print(\"Warning: High engagement. Please consider limiting screen time.\")\n",
    "elif prediction[0] == 3:\n",
    "    print(\"Warning: Moderate engagement. Ensure balanced usage.\")\n",
    "else:\n",
    "    print(\"Reward: Low engagement. Consider rewarding with more screen time.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
